{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":39763,"databundleVersionId":11756775,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Waveform Inversion for Subsurface Imaging - Kaggle Competition\n\n### 1. Imports and Setup\n In this section, I import all the required libraries.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\n\n# Reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:19:44.089509Z","iopub.execute_input":"2025-06-07T00:19:44.089771Z","iopub.status.idle":"2025-06-07T00:19:52.764415Z","shell.execute_reply.started":"2025-06-07T00:19:44.089748Z","shell.execute_reply":"2025-06-07T00:19:52.763558Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Load and Inspect Data\nI want to understand the shapes and patterns in the training data","metadata":{}},{"cell_type":"code","source":"train_data_dir = Path(\"/kaggle/input/waveform-inversion/train_samples/FlatVel_A\")\n\n# Load one sample to inspect shapes\nvelocity = np.load(train_data_dir / \"model/model2.npy\")\ndata = np.load(train_data_dir / \"data/data2.npy\")\nprint(\"Velocity map shape:\", velocity.shape)\nprint(\"Seismic data shape:\", data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:19:52.768152Z","iopub.execute_input":"2025-06-07T00:19:52.768685Z","iopub.status.idle":"2025-06-07T00:19:57.099223Z","shell.execute_reply.started":"2025-06-07T00:19:52.768656Z","shell.execute_reply":"2025-06-07T00:19:57.098193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Define Custom Dataset Class\nI create a PyTorch dataset that loads seismic data and its corresponding velocity maps\n","metadata":{}},{"cell_type":"code","source":"class FWI_Dataset(Dataset):\n    def __init__(self, data_paths, model_paths):\n        self.data_paths = data_paths\n        self.model_paths = model_paths\n\n    def __len__(self):\n        return len(self.data_paths)\n\n    def __getitem__(self, idx):\n        x = np.load(self.data_paths[idx])  # shape: (samples, sources, time, receivers)\n        y = np.load(self.model_paths[idx])  # shape: (samples, height, width)\n\n        # Normalize seismic data sample-wise\n        x = (x - x.mean()) / (x.std() + 1e-6)\n\n        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:20:40.849637Z","iopub.execute_input":"2025-06-07T00:20:40.849998Z","iopub.status.idle":"2025-06-07T00:20:40.856966Z","shell.execute_reply.started":"2025-06-07T00:20:40.849972Z","shell.execute_reply":"2025-06-07T00:20:40.856110Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Build the Model\nI'll use a small U-Net architecture to map seismic data to velocity maps\n","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder1 = DoubleConv(1, 32)\n        self.pool1 = nn.MaxPool2d(2)\n        self.encoder2 = DoubleConv(32, 64)\n\n        self.up = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n        self.decoder = DoubleConv(64, 32)\n        self.output_layer = nn.Conv2d(32, 1, kernel_size=1)\n\n    def forward(self, x):\n        x1 = self.encoder1(x)\n        x2 = self.encoder2(self.pool1(x1))\n        x = self.up(x2)\n        x = torch.cat([x1, x], dim=1)\n        x = self.decoder(x)\n        return self.output_layer(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:21:15.567828Z","iopub.execute_input":"2025-06-07T00:21:15.568189Z","iopub.status.idle":"2025-06-07T00:21:15.578736Z","shell.execute_reply.started":"2025-06-07T00:21:15.568162Z","shell.execute_reply":"2025-06-07T00:21:15.577547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Train the Model\nHere Iâ€™ll define a simple training loop","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion):\n    model.train()\n    running_loss = 0.0\n    for x, y in loader:\n        x = x.unsqueeze(1).to(device)  # Add channel dim\n        y = y.unsqueeze(1).to(device)\n\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    return running_loss / len(loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:21:49.269614Z","iopub.execute_input":"2025-06-07T00:21:49.270495Z","iopub.status.idle":"2025-06-07T00:21:49.276440Z","shell.execute_reply.started":"2025-06-07T00:21:49.270464Z","shell.execute_reply":"2025-06-07T00:21:49.275443Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Inference and Submission\nPredict and reshape into format","metadata":{}},{"cell_type":"code","source":"def predict_and_format(model, test_loader, sample_submission):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for x in test_loader:\n            x = x.unsqueeze(1).to(device)\n            preds = model(x).squeeze(1).cpu().numpy()\n            predictions.extend(preds)\n\n    # Only keep odd-indexed columns\n    output = []\n    for i, pred in enumerate(predictions):\n        for y in range(pred.shape[0]):\n            row = pred[y, ::2]  # odd-indexed columns\n            output.append([f\"testoid_y_{y}\"] + row.tolist())\n\n    columns = [\"oid_ypos\"] + sample_submission.columns[1:].tolist()\n    df = pd.DataFrame(output, columns=columns)\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:25:03.041684Z","iopub.execute_input":"2025-06-07T00:25:03.042057Z","iopub.status.idle":"2025-06-07T00:25:03.049378Z","shell.execute_reply.started":"2025-06-07T00:25:03.041998Z","shell.execute_reply":"2025-06-07T00:25:03.048360Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Visualizations\nI use a quick look at one seismic example and its corresponding velocity map\n","metadata":{}},{"cell_type":"code","source":"def visualize_sample(data_path, model_path):\n    seismic = np.load(data_path)[0]  # (sources, time, receivers)\n    velocity = np.load(model_path)[0]  # (height, width)\n\n    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n    axs[0].imshow(seismic.mean(axis=0), cmap=\"seismic\", aspect='auto')\n    axs[0].set_title(\"Seismic Data (mean over sources)\")\n    axs[1].imshow(velocity, cmap=\"viridis\")\n    axs[1].set_title(\"Velocity Map\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:25:06.665546Z","iopub.execute_input":"2025-06-07T00:25:06.666471Z","iopub.status.idle":"2025-06-07T00:25:06.671891Z","shell.execute_reply.started":"2025-06-07T00:25:06.666439Z","shell.execute_reply":"2025-06-07T00:25:06.670917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pair of files to visualize\nsample_data_path = \"/kaggle/input/waveform-inversion/train_samples/FlatVel_A/data/data2.npy\"\nsample_model_path = \"/kaggle/input/waveform-inversion/train_samples/FlatVel_A/model/model2.npy\"\n\nvisualize_sample(sample_data_path, sample_model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T00:26:27.004301Z","iopub.execute_input":"2025-06-07T00:26:27.004595Z","iopub.status.idle":"2025-06-07T00:26:27.736312Z","shell.execute_reply.started":"2025-06-07T00:26:27.004575Z","shell.execute_reply":"2025-06-07T00:26:27.735077Z"}},"outputs":[],"execution_count":null}]}